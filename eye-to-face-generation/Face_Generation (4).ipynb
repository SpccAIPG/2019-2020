{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Face Generation.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig4nUDtjc0YE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2003ab1f-affe-4a20-9d27-9aa8d0ed0284"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTVJFVtyAdOT",
        "trusted": true
      },
      "source": [
        "import tensorflow as tf\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4hrQLVTtXs1"
      },
      "source": [
        "# Global Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adgBMvSbKhLp"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKAJxMU9C-gl",
        "trusted": true
      },
      "source": [
        "# Basic Settings\n",
        "raw_path = r\"/content/drive/MyDrive/celeba/img_align_celeba/\"\n",
        "test_raw_path = r\"/content/drive/MyDrive/celeba/test/\"\n",
        "cascade_path = r\"/content/drive/MyDrive/celeba/cascade/\"\n",
        "data_path = r\"/content/drive/MyDrive/celeba/data.pkl\"\n",
        "model_path = r\"/content/drive/MyDrive/face generation (fl)/model/\"\n",
        "output_path = r\"/content/drive/MyDrive/face generation (fl)/output/\"\n",
        "eye_size = 32\n",
        "face_size = 128\n",
        "epoch_size = 7500\n",
        "batch_size = 64\n",
        "# Optimizer\n",
        "optimizer_name = \"Adam\"\n",
        "from tensorflow.keras.optimizers import Adam as optimizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxaI7pHCKjlL"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVgsCmKrFQwW",
        "trusted": true
      },
      "source": [
        "def normalize(img):\n",
        "    return cv2.normalize(img.astype(\"float32\"),None,0.0,1.0,cv2.NORM_MINMAX)\n",
        "def restore(img_norm):\n",
        "    return (img_norm * 255).astype(\"uint8\")\n",
        "def crop(raw_file_path):\n",
        "    eye_list = []\n",
        "    face_list = []\n",
        "    raw = cv2.imread(raw_file_path)\n",
        "    face = cv2.CascadeClassifier(cascade_path + \"face_cascade.xml\").detectMultiScale(cv2.cvtColor(raw,cv2.COLOR_BGR2GRAY))\n",
        "    if len(face) == 1:\n",
        "        face = raw[face[0][1]:face[0][1]+face[0][3],face[0][0]:face[0][0]+face[0][2]]\n",
        "        face_processed = normalize(cv2.resize(face,(face_size,face_size)))\n",
        "        for i in range(2):\n",
        "            face_list.append(face_processed)\n",
        "    else:\n",
        "        raise RuntimeError(\"A singular face cannot be detected\")\n",
        "    eyes = cv2.CascadeClassifier(cascade_path + \"eye_cascade.xml\").detectMultiScale(cv2.cvtColor(face,cv2.COLOR_BGR2GRAY))\n",
        "    if(len(eyes) == 2):\n",
        "        for i in range(2):\n",
        "            eye_list.append(normalize(cv2.resize(face[eyes[i][1]:eyes[i][1]+eyes[i][3],eyes[i][0]:eyes[i][0]+eyes[i][2]],(eye_size,eye_size))))\n",
        "    else:\n",
        "        raise RuntimeError(\"The number of eyes detected is not 2\")\n",
        "    return [eye_list,face_list]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCoj1FQeCsN8"
      },
      "source": [
        "# Data Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqQqYn1tdXK"
      },
      "source": [
        "## Make Data File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwkODIe4sa0L",
        "trusted": false
      },
      "source": [
        "import os, cv2, pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "data = [[],[]]\n",
        "data_n = 0\n",
        "with tqdm(total = epoch_size) as phar:\n",
        "    for raw_file_name in os.listdir(raw_path):\n",
        "        try:\n",
        "            data_item = crop(raw_path + raw_file_name)\n",
        "            data[0] += data_item[0]\n",
        "            data[1] += data_item[1]\n",
        "        except:\n",
        "            continue\n",
        "        data_n += 1\n",
        "        phar.update(1)\n",
        "        if data_n == epoch_size:\n",
        "            break\n",
        "with open(data_path,\"wb\") as data_raw:\n",
        "    pickle.dump([np.array(data[0]),np.array(data[1])],data_raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhU9dVSACMAs"
      },
      "source": [
        "## Load Data File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjPzdyBjAUDG",
        "trusted": true
      },
      "source": [
        "import pickle\n",
        "with open(data_path,\"rb\") as data_raw:\n",
        "    data = pickle.load(data_raw)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhudHmwBBd2D"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fMWmoJfxYkO"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0axM-EUxRDb",
        "trusted": true
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.activations import *\n",
        "class _model:\n",
        "    @property\n",
        "    def _dim(self):\n",
        "        return int(face_size * 1.5)\n",
        "    def load(self,path):\n",
        "        self._main = load_model(path,custom_objects = catalog)\n",
        "    def save(self,path):\n",
        "        self._main.save(path)\n",
        "    def train(self,input_batch,output_batch):\n",
        "        return self._main.train_on_batch(input_batch,output_batch)\n",
        "    def fit(self,*args,**kwargs):\n",
        "        return self._main.fit(*args,**kwargs)\n",
        "    def test(self,input_batch,output_batch):\n",
        "        return self._main.evaluate(input_batch,output_batch)\n",
        "    def predict(self,input_batch):\n",
        "        return self._main.predict(input_batch)\n",
        "class generator(_model):\n",
        "    def _add_block(self,layer,filter,pooling = 0,kernel_size = (3,3)):\n",
        "        if(pooling > 0):\n",
        "            layer = Conv2D(filter,kernel_size,strides = pooling,padding = \"same\")(layer)\n",
        "        elif(pooling < 0):\n",
        "            layer = Conv2DTranspose(filter,kernel_size,strides = -pooling,padding = \"same\")(layer)\n",
        "        else:\n",
        "            layer = Conv2D(filter,kernel_size,padding = \"same\")(layer)\n",
        "        layer = BatchNormalization()(layer)\n",
        "        return LeakyReLU(0.3)(layer)\n",
        "    def _add_dense_block(self,layer,units):\n",
        "        layer = Dense(units)(layer)\n",
        "        layer = BatchNormalization()(layer)\n",
        "        return LeakyReLU(0.3)(layer)\n",
        "    def __init__(self):\n",
        "        # Encoder\n",
        "        main_input = Input((eye_size,eye_size,3))\n",
        "        dim = 32\n",
        "        main = self._add_block(main_input,dim)\n",
        "        for i in range(int(np.log2(eye_size) - 2)):\n",
        "            dim *= 2\n",
        "            main = self._add_block(main,dim,2)\n",
        "            main = self._add_block(main,dim)\n",
        "        main = Flatten()(main)\n",
        "        main = self._add_dense_block(main,face_size)\n",
        "        # Decoder\n",
        "        dim = self._dim\n",
        "        main = self._add_dense_block(main,16 * dim)\n",
        "        main = Reshape((4,4,dim))(main)\n",
        "        main = self._add_block(main,self._dim)\n",
        "        main = self._add_block(main,self._dim)\n",
        "        for i in range(int(np.log2(face_size) - 2)):\n",
        "            dim //= 2\n",
        "            main = self._add_block(main,dim,-2)\n",
        "            main = self._add_block(main,dim)\n",
        "        # Converter\n",
        "        main = Conv2D(3,(3,3),padding = \"same\")(main)\n",
        "        main = Activation(\"sigmoid\")(main)\n",
        "        self._main = Model(main_input,main)\n",
        "        self._main.compile(optimizer = optimizer(),loss = \"mae\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giKiMFI6BLLB"
      },
      "source": [
        "## WGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eelP73Nm8fiw"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NBnPPZA7qMa",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "9a762634-4eae-4d89-c9ab-7240f9a945d4"
      },
      "source": [
        "class WGAN(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        discriminator,\n",
        "        generator,\n",
        "        discriminator_extra_steps=3,\n",
        "        gp_weight=10.0,\n",
        "    ):\n",
        "        super(WGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.d_steps = discriminator_extra_steps\n",
        "        self.gp_weight = gp_weight\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
        "        super(WGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_loss_fn = d_loss_fn\n",
        "        self.g_loss_fn = g_loss_fn\n",
        "\n",
        "    def gradient_penalty(self, batch_size, real_images, fake_images, eye_images):\n",
        "        \"\"\" Calculates the gradient penalty.\n",
        "\n",
        "        This loss is calculated on an interpolated image\n",
        "        and added to the discriminator loss.\n",
        "        \"\"\"\n",
        "        # get the interplated image\n",
        "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
        "        diff = fake_images - real_images\n",
        "        interpolated = real_images + alpha * diff\n",
        "\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            # 1. Get the discriminator output for this interpolated image.\n",
        "            pred = self.discriminator([interpolated,eye_images], training=True)\n",
        "\n",
        "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
        "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "        # 3. Calcuate the norm of the gradients\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "        return gp\n",
        "\n",
        "    def train_step(self, data):\n",
        "        eye_images, real_images = data\n",
        "\n",
        "        # Get the batch size\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        # For each batch, we are going to perform the\n",
        "        # following steps as laid out in the original paper.\n",
        "        # 1. Train the generator and get the generator loss\n",
        "        # 2. Train the discriminator and get the discriminator loss\n",
        "        # 3. Calculate the gradient penalty\n",
        "        # 4. Multiply this gradient penalty with a constant weight factor\n",
        "        # 5. Add gradient penalty to the discriminator loss\n",
        "        # 6. Return generator and discriminator losses as a loss dictionary.\n",
        "\n",
        "        # Train discriminator first. The original paper recommends training\n",
        "        # the discriminator for `x` more steps (typically 5) as compared to\n",
        "        # one step of the generator. Here we will train it for 3 extra steps\n",
        "        # as compared to 5 to reduce the training time.\n",
        "        for i in range(self.d_steps):\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Generate fake images from the latent vector\n",
        "                fake_images = self.generator(eye_images, training=True)\n",
        "                # Get the logits for the fake images\n",
        "                fake_logits = self.discriminator([fake_images,eye_images], training=True)\n",
        "                # Get the logits for real images\n",
        "                real_logits = self.discriminator([real_images,eye_images], training=True)\n",
        "\n",
        "                # Calculate discriminator loss using fake and real logits\n",
        "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
        "                # Calculate the gradient penalty\n",
        "                gp = self.gradient_penalty(batch_size, real_images, fake_images, eye_images)\n",
        "                # Add the gradient penalty to the original discriminator loss\n",
        "                d_loss = d_cost + gp * self.gp_weight\n",
        "\n",
        "            # Get the gradients w.r.t the discriminator loss\n",
        "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "            # Update the weights of the discriminator using the discriminator optimizer\n",
        "            self.d_optimizer.apply_gradients(\n",
        "                zip(d_gradient, self.discriminator.trainable_variables)\n",
        "            )\n",
        "\n",
        "        # Train the generator now.\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Generate fake images using the generator\n",
        "            generated_images = self.generator(eye_images, training=True)\n",
        "            # Get the discriminator logits for fake images\n",
        "            gen_img_logits = self.discriminator([generated_images,eye_images], training=True)\n",
        "            # Calculate the generator loss\n",
        "            g_loss = self.g_loss_fn(gen_img_logits)\n",
        "\n",
        "        # Get the gradients w.r.t the generator loss\n",
        "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        # Update the weights of the generator using the generator optimizer\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gen_gradient, self.generator.trainable_variables)\n",
        "        )\n",
        "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
        "def w_loss_g(fake_img):\n",
        "    return -tf.reduce_mean(fake_img)\n",
        "def w_loss_d(real_img,fake_img):\n",
        "    real_loss = tf.reduce_mean(real_img)\n",
        "    fake_loss = tf.reduce_mean(fake_img)\n",
        "    return fake_loss - real_loss\n",
        "def s_adam():\n",
        "    return Adam(learning_rate=0.0002,beta_1=0.5,beta_2=0.9)\n",
        "catalog = {\n",
        "    \"w_loss_g\": w_loss_g,\n",
        "    \"w_loss_d\": w_loss_d,\n",
        "    \"s_adam\": s_adam,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e478d4f0785d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def __init__(\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnk_q2rmx-5F",
        "trusted": false
      },
      "source": [
        "class discriminator(_model):\n",
        "    def _add_block(self,layer,filter,kernel_size = (3,3),strides = 1):\n",
        "        if(strides < 1):\n",
        "            layer = Conv2DTranspose(filter,kernel_size,strides = int(1 / strides),padding = \"same\")(layer)\n",
        "        else:\n",
        "            layer = Conv2D(filter,kernel_size,strides = int(strides),padding = \"same\")(layer)\n",
        "        return LeakyReLU(0.3)(layer)\n",
        "    def __init__(self):\n",
        "        main_input = Input((face_size,face_size,3))\n",
        "        cond_input = Input((eye_size,eye_size,3))\n",
        "        cond = self._add_block(cond_input,3,(3,3),eye_size / face_size)\n",
        "        main = concatenate([main_input,cond])\n",
        "        dim = 16\n",
        "        main = self._add_block(main,dim,(3,3))\n",
        "        main = self._add_block(main,dim,(3,3))\n",
        "        for i in range(int(np.log2(face_size) - 2)):\n",
        "            dim *= 2\n",
        "            main = self._add_block(main,dim,(3,3),2)\n",
        "            main = self._add_block(main,dim,(3,3))\n",
        "        main = Flatten()(main)\n",
        "        main = Dense(1)(main)\n",
        "        self._main = Model([main_input,cond_input],main)\n",
        "class combined(_model):\n",
        "    def __init__(self,generator,discriminator):\n",
        "        self._main = WGAN(discriminator = discriminator._main,generator = generator._main)\n",
        "        self._main.compile(\n",
        "            d_optimizer = s_adam(),\n",
        "            g_optimizer = s_adam(),\n",
        "            d_loss_fn = w_loss_d,\n",
        "            g_loss_fn = w_loss_g\n",
        "        )\n",
        "    def save(self,path):\n",
        "        self._main.generator.save(path + \"_generator.h5\")\n",
        "        self._main.discriminator.save(path + \"_discriminator.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnU-9vMh7Ber"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hLjXFUb7DjJ",
        "trusted": false
      },
      "source": [
        "g = generator()\n",
        "g.load(model_path + \"wgan_generator.h5\")\n",
        "d = discriminator()\n",
        "d.load(model_path + \"wgan_discriminator.h5\")\n",
        "c = combined(g,d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj6_1qDl6-Va"
      },
      "source": [
        "### New Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8fEnyo7SjDL",
        "trusted": false
      },
      "source": [
        "g = generator()\n",
        "d = discriminator()\n",
        "c = combined(g,d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC3_jkI8w2On"
      },
      "source": [
        "## Feature Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqnv64V6BNhJ"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJsPDPTrw4ee",
        "trusted": true
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications import VGG19\n",
        "class vgg(_model):\n",
        "    @staticmethod\n",
        "    def preprocess(img):\n",
        "        return img * 255 - [103.939,116.779,123.68]\n",
        "    def __init__(self):\n",
        "        main_input = Input((face_size,face_size,3))\n",
        "        main = Lambda(self.preprocess)(main_input)\n",
        "        vgg = VGG19(input_shape = (face_size,face_size,3),include_top = False)\n",
        "        vgg_output = []\n",
        "        for l in vgg.layers:\n",
        "            vgg_output.append(l.output)\n",
        "        vgg = Model(vgg.input,vgg_output)\n",
        "        vgg = vgg(main)\n",
        "        self._main = Model(main_input,vgg)\n",
        "        self._main.compile(optimizer = optimizer(),loss = \"mae\")\n",
        "        self._main.trainable = False\n",
        "class combined_loss(Loss):\n",
        "    def __init__(self,mae_weight = 0.85,sdl_weight = 0.15,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.mae_weight = mae_weight\n",
        "        self.sdl_weight = sdl_weight\n",
        "    @staticmethod\n",
        "    def _vector_std(matrix):\n",
        "        return K.mean(K.mean((cosine_similarity(K.mean(matrix,axis = 0),matrix) + 1) / 2,axis = 0))\n",
        "    @classmethod\n",
        "    def vector_std_loss(cls,y_true,y_pred):\n",
        "        return K.abs(cls._vector_std(y_true) - cls._vector_std(y_pred))\n",
        "    def call(self,y_true,y_pred):\n",
        "        y_true = K.constant(y_true)\n",
        "        y_pred = K.constant(y_pred)\n",
        "        return (\n",
        "            MeanAbsoluteError()(y_true,y_pred) * self.mae_weight +\n",
        "            self.vector_std_loss(y_true,y_pred) * self.sdl_weight\n",
        "        )\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            \"mae_weight\": self.mae_weight,\n",
        "            \"sdl_weight\": self.sdl_weight,\n",
        "        }\n",
        "    @classmethod\n",
        "    def from_config(cls,config):\n",
        "        return cls(**config)\n",
        "def weight_function_linear(sum,layer_n,focus):\n",
        "    layer_n -= 1\n",
        "    max = 2 * sum / layer_n\n",
        "    def weight_function(i):\n",
        "        if 0 <= i <= focus:\n",
        "            return max * i / focus\n",
        "        elif focus <= i <= layer_n:\n",
        "            return (max / (layer_n - focus)) * (layer_n - i)\n",
        "    return weight_function\n",
        "class combined(_model):\n",
        "    class _base_model(Model):\n",
        "        def __init__(self,inputs,outputs,**kwargs):\n",
        "            super().__init__(inputs,outputs,**kwargs)\n",
        "        def train_step(self,data):\n",
        "            x,y = data\n",
        "            return super().train_step((x,[y] + self.layers[2](y)))\n",
        "        def evaluate(self,x,y,**kwargs):\n",
        "            return super().evaluate(x,[y] + self.layers[2](y),**kwargs)\n",
        "        def compile(self,optimizer,**kwargs):\n",
        "            kwargs[\"run_eagerly\"] = True\n",
        "            return super().compile(optimizer,**kwargs)\n",
        "        \n",
        "    def __init__(self,generator,vgg,mae_loss_weight = 0.85,sdl_loss_weight = 0.15,loss_weight_balance = True,data_sample = None,g_loss_weight = 0.1,vgg_loss_weight = 0.9,loss_weight_function = weight_function_linear,loss_weight_args = {\"focus\": 10}):\n",
        "        # Combine the generator and the vgg model\n",
        "        main_input = Input((eye_size,eye_size,3))\n",
        "        main = generator._main(main_input)\n",
        "        main_vgg = vgg._main(main)\n",
        "        self._main = self._base_model(main_input,[main] + main_vgg)\n",
        "        # Estimate the scale of losses\n",
        "        if loss_weight_balance == True:\n",
        "            loss_list = []\n",
        "            self._main.compile(optimizer = optimizer(),loss = \"mae\")\n",
        "            mae_loss_base = self.test(*data_sample)\n",
        "            self._main.compile(optimizer = optimizer(),loss = combined_loss.vector_std_loss)\n",
        "            sdl_loss_base = self.test(*data_sample)\n",
        "            for i in range(len(mae_loss_base)):\n",
        "                loss_list.append(combined_loss(mae_loss_weight / mae_loss_base[i],sdl_loss_weight / sdl_loss_base[i]))\n",
        "        else:\n",
        "            loss_list = combined_loss(mae_loss_weight,sdl_loss_weight)\n",
        "        # Determine the weightings of the losses\n",
        "        loss_weight = []\n",
        "        loss_weight.append(g_loss_weight)\n",
        "        layer_n = len(main_vgg)\n",
        "        loss_weight_function = loss_weight_function(vgg_loss_weight,layer_n,**loss_weight_args)\n",
        "        for i in range(layer_n):\n",
        "            loss_weight.append(loss_weight_function(i))\n",
        "        self._main.compile(optimizer = optimizer(),loss = loss_list,loss_weights = loss_weight)\n",
        "        print(\"Loss weights: \" + str(loss_weight))\n",
        "catalog = {\n",
        "    \"combined_loss\": combined_loss,\n",
        "    \"_base_model\": combined._base_model,\n",
        "    \"preprocess\": vgg.preprocess,\n",
        "    optimizer_name: optimizer,\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roOZTrGkQCcp"
      },
      "source": [
        "### New Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAz87-roPtSp",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0cc810-4c7c-4081-bb74-6bc766433404"
      },
      "source": [
        "g = generator()\n",
        "v = vgg()\n",
        "c = combined(g,v,mae_loss_weight = 0.85,sdl_loss_weight = 0.15,g_loss_weight = 0,vgg_loss_weight = 1,loss_weight_balance = True,data_sample = [data[0][:32],data[1][:32]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 868ms/step - loss: 4074.5144 - model_loss: 0.2357 - model_2_loss: 60.1089 - model_2_1_loss: 21.7223 - model_2_2_loss: 88.9057 - model_2_3_loss: 105.9015 - model_2_4_loss: 105.0493 - model_2_5_loss: 99.4199 - model_2_6_loss: 164.0371 - model_2_7_loss: 123.3669 - model_2_8_loss: 159.8085 - model_2_9_loss: 345.4131 - model_2_10_loss: 518.2451 - model_2_11_loss: 773.3022 - model_2_12_loss: 535.0903 - model_2_13_loss: 389.5014 - model_2_14_loss: 245.0066 - model_2_15_loss: 68.2873 - model_2_16_loss: 151.4157 - model_2_17_loss: 71.3913 - model_2_18_loss: 33.6025 - model_2_19_loss: 12.8895 - model_2_20_loss: 0.5864 - model_2_21_loss: 1.2273\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 2.4744 - model_loss: 0.0086 - model_2_loss: 0.1817 - model_2_1_loss: 0.1062 - model_2_2_loss: 0.0711 - model_2_3_loss: 0.0670 - model_2_4_loss: 0.0941 - model_2_5_loss: 0.1578 - model_2_6_loss: 0.1263 - model_2_7_loss: 0.1313 - model_2_8_loss: 0.1104 - model_2_9_loss: 0.0738 - model_2_10_loss: 0.0919 - model_2_11_loss: 0.0721 - model_2_12_loss: 0.0918 - model_2_13_loss: 0.1162 - model_2_14_loss: 0.1322 - model_2_15_loss: 0.1640 - model_2_16_loss: 0.1287 - model_2_17_loss: 0.1033 - model_2_18_loss: 0.0819 - model_2_19_loss: 0.0773 - model_2_20_loss: 0.1618 - model_2_21_loss: 0.1250\n",
            "Loss weights: [0, 0.0, 0.009523809523809523, 0.019047619047619046, 0.02857142857142857, 0.03809523809523809, 0.047619047619047616, 0.05714285714285714, 0.06666666666666667, 0.07619047619047618, 0.08571428571428572, 0.09523809523809523, 0.08658008658008658, 0.07792207792207792, 0.06926406926406926, 0.06060606060606061, 0.05194805194805195, 0.04329004329004329, 0.03463203463203463, 0.025974025974025976, 0.017316017316017316, 0.008658008658008658, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3rvwInP8Xg5"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfrLgST08Wl8",
        "trusted": false
      },
      "source": [
        "c = load_model(model_path + \"main.h5\",custom_objects = catalog)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rEP-my8qJ4e"
      },
      "source": [
        "c.save_weights(\"weight.h5\")\r\n",
        "with open(\"optimizer.pkl\",\"wb\") as f:\r\n",
        "    pickle.dump(c.optimizer.get_weights(),f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17E46HRQ-uwZ"
      },
      "source": [
        "with open(\"optimizer.pkl\",\"rb\") as f:\r\n",
        "    opt_weights = pickle.load(f)\r\n",
        "grad_vars = c._main.trainable_weights\r\n",
        "zero_grads = [tf.zeros_like(w) for w in grad_vars]\r\n",
        "c._main.optimizer.apply_gradients(zip(zero_grads, grad_vars))\r\n",
        "c._main.optimizer.set_weights(opt_weights)\r\n",
        "c._main.load_weights(\"weight.h5\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxUtg703yA0E"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-1r_TaeyDEX",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eeddb60-4ada-40b5-e542-6c7c2297c344"
      },
      "source": [
        "import os, cv2\n",
        "def test(generator):\n",
        "    for raw_file_name in os.listdir(test_raw_path):\n",
        "        try:\n",
        "            data_item = crop(test_raw_path + raw_file_name)\n",
        "        except:\n",
        "            continue\n",
        "        eye = np.array(data_item[0])\n",
        "        face = np.array(data_item[1])\n",
        "        generator.test(eye,face)\n",
        "        face_pred = generator.predict(eye)\n",
        "        for i in range(2):\n",
        "            cv2.imwrite(output_path + raw_file_name + \"_eye_\" + str(i) + \".jpg\",restore(eye[i]))\n",
        "            cv2.imwrite(output_path + raw_file_name + \"_face_\" + str(i) + \".jpg\",restore(face[i]))\n",
        "            cv2.imwrite(output_path + raw_file_name + \"_pred_\" + str(i) + \".jpg\",restore(face_pred[i]))\n",
        "for i in range(13):\n",
        "    print(\"Epoch \" + str(i + 1) + \":\")\n",
        "    c.fit(data[0],data[1],batch_size = 64)\n",
        "    test(g)\n",
        "    c.save(model_path + \"main.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "235/235 [==============================] - 273s 1s/step - loss: 0.5488 - model_loss: 2.3455e-04 - model_2_loss: 86.7126 - model_2_1_loss: 0.1375 - model_2_2_loss: 1.5608 - model_2_3_loss: 0.4462 - model_2_4_loss: 0.4960 - model_2_5_loss: 0.6434 - model_2_6_loss: 0.9476 - model_2_7_loss: 0.4132 - model_2_8_loss: 0.6377 - model_2_9_loss: 0.8457 - model_2_10_loss: 0.6515 - model_2_11_loss: 0.5688 - model_2_12_loss: 0.2905 - model_2_13_loss: 0.3384 - model_2_14_loss: 0.3234 - model_2_15_loss: 0.1699 - model_2_16_loss: 1.1740 - model_2_17_loss: 0.2230 - model_2_18_loss: 0.2001 - model_2_19_loss: 0.1664 - model_2_20_loss: 0.0340 - model_2_21_loss: 1.2318\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 0.1870\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1667\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1530\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2257\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1582\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2226\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1927\n",
            "Epoch 2:\n",
            "235/235 [==============================] - 271s 1s/step - loss: 0.5488 - model_loss: 2.2831e-04 - model_2_loss: 86.9098 - model_2_1_loss: 0.1377 - model_2_2_loss: 1.5606 - model_2_3_loss: 0.4463 - model_2_4_loss: 0.4960 - model_2_5_loss: 0.6430 - model_2_6_loss: 0.9471 - model_2_7_loss: 0.4131 - model_2_8_loss: 0.6376 - model_2_9_loss: 0.8455 - model_2_10_loss: 0.6514 - model_2_11_loss: 0.5686 - model_2_12_loss: 0.2906 - model_2_13_loss: 0.3386 - model_2_14_loss: 0.3236 - model_2_15_loss: 0.1700 - model_2_16_loss: 1.1738 - model_2_17_loss: 0.2232 - model_2_18_loss: 0.2004 - model_2_19_loss: 0.1672 - model_2_20_loss: 0.0351 - model_2_21_loss: 1.2330\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1612\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1740\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1496\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2196\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1789\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2070\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1870\n",
            "Epoch 3:\n",
            "235/235 [==============================] - 271s 1s/step - loss: 0.5485 - model_loss: 2.2916e-04 - model_2_loss: 86.9934 - model_2_1_loss: 0.1378 - model_2_2_loss: 1.5604 - model_2_3_loss: 0.4463 - model_2_4_loss: 0.4959 - model_2_5_loss: 0.6429 - model_2_6_loss: 0.9469 - model_2_7_loss: 0.4130 - model_2_8_loss: 0.6374 - model_2_9_loss: 0.8451 - model_2_10_loss: 0.6510 - model_2_11_loss: 0.5682 - model_2_12_loss: 0.2903 - model_2_13_loss: 0.3382 - model_2_14_loss: 0.3233 - model_2_15_loss: 0.1697 - model_2_16_loss: 1.1733 - model_2_17_loss: 0.2229 - model_2_18_loss: 0.2000 - model_2_19_loss: 0.1666 - model_2_20_loss: 0.0345 - model_2_21_loss: 1.2322\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1742\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1658\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1541\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2134\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1585\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2079\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1775\n",
            "Epoch 4:\n",
            "235/235 [==============================] - 270s 1s/step - loss: 0.5481 - model_loss: 2.2856e-04 - model_2_loss: 86.8871 - model_2_1_loss: 0.1376 - model_2_2_loss: 1.5577 - model_2_3_loss: 0.4455 - model_2_4_loss: 0.4955 - model_2_5_loss: 0.6424 - model_2_6_loss: 0.9460 - model_2_7_loss: 0.4126 - model_2_8_loss: 0.6368 - model_2_9_loss: 0.8443 - model_2_10_loss: 0.6506 - model_2_11_loss: 0.5677 - model_2_12_loss: 0.2903 - model_2_13_loss: 0.3382 - model_2_14_loss: 0.3233 - model_2_15_loss: 0.1699 - model_2_16_loss: 1.1721 - model_2_17_loss: 0.2229 - model_2_18_loss: 0.2001 - model_2_19_loss: 0.1668 - model_2_20_loss: 0.0352 - model_2_21_loss: 1.2308\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1820\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1669\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1598\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2121\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1608\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1970\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1991\n",
            "Epoch 5:\n",
            "235/235 [==============================] - 270s 1s/step - loss: 0.5476 - model_loss: 2.2833e-04 - model_2_loss: 86.9268 - model_2_1_loss: 0.1375 - model_2_2_loss: 1.5573 - model_2_3_loss: 0.4454 - model_2_4_loss: 0.4950 - model_2_5_loss: 0.6417 - model_2_6_loss: 0.9452 - model_2_7_loss: 0.4122 - model_2_8_loss: 0.6362 - model_2_9_loss: 0.8435 - model_2_10_loss: 0.6500 - model_2_11_loss: 0.5673 - model_2_12_loss: 0.2899 - model_2_13_loss: 0.3378 - model_2_14_loss: 0.3229 - model_2_15_loss: 0.1698 - model_2_16_loss: 1.1709 - model_2_17_loss: 0.2226 - model_2_18_loss: 0.2000 - model_2_19_loss: 0.1667 - model_2_20_loss: 0.0342 - model_2_21_loss: 1.2296\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2038\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1671\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1536\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2153\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1553\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2205\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1987\n",
            "Epoch 6:\n",
            "235/235 [==============================] - 270s 1s/step - loss: 0.5472 - model_loss: 2.2848e-04 - model_2_loss: 86.8948 - model_2_1_loss: 0.1376 - model_2_2_loss: 1.5567 - model_2_3_loss: 0.4453 - model_2_4_loss: 0.4948 - model_2_5_loss: 0.6417 - model_2_6_loss: 0.9449 - model_2_7_loss: 0.4120 - model_2_8_loss: 0.6359 - model_2_9_loss: 0.8430 - model_2_10_loss: 0.6495 - model_2_11_loss: 0.5669 - model_2_12_loss: 0.2896 - model_2_13_loss: 0.3375 - model_2_14_loss: 0.3225 - model_2_15_loss: 0.1695 - model_2_16_loss: 1.1700 - model_2_17_loss: 0.2224 - model_2_18_loss: 0.1997 - model_2_19_loss: 0.1666 - model_2_20_loss: 0.0341 - model_2_21_loss: 1.2287\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1822\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1673\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1611\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2149\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1722\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2057\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1891\n",
            "Epoch 7:\n",
            "235/235 [==============================] - 270s 1s/step - loss: 0.5469 - model_loss: 2.2799e-04 - model_2_loss: 86.8221 - model_2_1_loss: 0.1373 - model_2_2_loss: 1.5555 - model_2_3_loss: 0.4449 - model_2_4_loss: 0.4946 - model_2_5_loss: 0.6416 - model_2_6_loss: 0.9447 - model_2_7_loss: 0.4120 - model_2_8_loss: 0.6356 - model_2_9_loss: 0.8425 - model_2_10_loss: 0.6492 - model_2_11_loss: 0.5665 - model_2_12_loss: 0.2894 - model_2_13_loss: 0.3372 - model_2_14_loss: 0.3223 - model_2_15_loss: 0.1692 - model_2_16_loss: 1.1694 - model_2_17_loss: 0.2220 - model_2_18_loss: 0.1990 - model_2_19_loss: 0.1657 - model_2_20_loss: 0.0347 - model_2_21_loss: 1.2282\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1775\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1706\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1529\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2303\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1750\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1883\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1883\n",
            "Epoch 8:\n",
            "235/235 [==============================] - 270s 1s/step - loss: 0.5467 - model_loss: 2.2866e-04 - model_2_loss: 86.8799 - model_2_1_loss: 0.1371 - model_2_2_loss: 1.5553 - model_2_3_loss: 0.4446 - model_2_4_loss: 0.4943 - model_2_5_loss: 0.6412 - model_2_6_loss: 0.9442 - model_2_7_loss: 0.4117 - model_2_8_loss: 0.6353 - model_2_9_loss: 0.8422 - model_2_10_loss: 0.6489 - model_2_11_loss: 0.5663 - model_2_12_loss: 0.2893 - model_2_13_loss: 0.3372 - model_2_14_loss: 0.3222 - model_2_15_loss: 0.1694 - model_2_16_loss: 1.1688 - model_2_17_loss: 0.2220 - model_2_18_loss: 0.1993 - model_2_19_loss: 0.1661 - model_2_20_loss: 0.0350 - model_2_21_loss: 1.2291\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1783\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1656\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1510\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2187\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1559\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2126\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1852\n",
            "Epoch 9:\n",
            "235/235 [==============================] - 270s 1s/step - loss: 0.5457 - model_loss: 2.2845e-04 - model_2_loss: 86.8461 - model_2_1_loss: 0.1370 - model_2_2_loss: 1.5526 - model_2_3_loss: 0.4438 - model_2_4_loss: 0.4935 - model_2_5_loss: 0.6405 - model_2_6_loss: 0.9432 - model_2_7_loss: 0.4111 - model_2_8_loss: 0.6344 - model_2_9_loss: 0.8410 - model_2_10_loss: 0.6476 - model_2_11_loss: 0.5654 - model_2_12_loss: 0.2886 - model_2_13_loss: 0.3362 - model_2_14_loss: 0.3214 - model_2_15_loss: 0.1686 - model_2_16_loss: 1.1670 - model_2_17_loss: 0.2214 - model_2_18_loss: 0.1987 - model_2_19_loss: 0.1655 - model_2_20_loss: 0.0344 - model_2_21_loss: 1.2258\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1753\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1710\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1589\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2240\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1676\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2215\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1927\n",
            "Epoch 10:\n",
            "235/235 [==============================] - 270s 1s/step - loss: 0.5452 - model_loss: 2.2822e-04 - model_2_loss: 86.6535 - model_2_1_loss: 0.1369 - model_2_2_loss: 1.5504 - model_2_3_loss: 0.4433 - model_2_4_loss: 0.4931 - model_2_5_loss: 0.6399 - model_2_6_loss: 0.9423 - model_2_7_loss: 0.4107 - model_2_8_loss: 0.6338 - model_2_9_loss: 0.8401 - model_2_10_loss: 0.6471 - model_2_11_loss: 0.5648 - model_2_12_loss: 0.2883 - model_2_13_loss: 0.3359 - model_2_14_loss: 0.3211 - model_2_15_loss: 0.1684 - model_2_16_loss: 1.1659 - model_2_17_loss: 0.2211 - model_2_18_loss: 0.1983 - model_2_19_loss: 0.1652 - model_2_20_loss: 0.0342 - model_2_21_loss: 1.2247\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1901\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1637\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1567\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2007\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1686\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2065\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1919\n",
            "Epoch 11:\n",
            "134/235 [================>.............] - ETA: 1:56 - loss: 0.5425 - model_loss: 2.2559e-04 - model_2_loss: 86.1832 - model_2_1_loss: 0.1360 - model_2_2_loss: 1.5417 - model_2_3_loss: 0.4406 - model_2_4_loss: 0.4908 - model_2_5_loss: 0.6377 - model_2_6_loss: 0.9386 - model_2_7_loss: 0.4089 - model_2_8_loss: 0.6308 - model_2_9_loss: 0.8359 - model_2_10_loss: 0.6438 - model_2_11_loss: 0.5617 - model_2_12_loss: 0.2867 - model_2_13_loss: 0.3342 - model_2_14_loss: 0.3196 - model_2_15_loss: 0.1677 - model_2_16_loss: 1.1600 - model_2_17_loss: 0.2199 - model_2_18_loss: 0.1971 - model_2_19_loss: 0.1642 - model_2_20_loss: 0.0343 - model_2_21_loss: 1.2161"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5hOaruZ-1nk",
        "trusted": true
      },
      "source": [
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}